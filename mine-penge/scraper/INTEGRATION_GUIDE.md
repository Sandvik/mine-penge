# Mine Penge Scraper Integration Guide

Denne guide forklarer hvordan Scraper projektet kan integreres i minepenge.dk projektet.

## ğŸ“ Anbefalede Placeringer

### Mulighed 1: Separat mappe (Anbefalet)
```
minepenge/
â”œâ”€â”€ scraper/                    # Hele Scraper mappen
â”‚   â”œâ”€â”€ update_all_data.py
â”‚   â”œâ”€â”€ update_all_data_realtime.py
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ tagging/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ frontend/
â”œâ”€â”€ backend/
â””â”€â”€ ...
```

### Mulighed 2: Som backend komponent
```
minepenge/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ scraper/               # Scraper som backend komponent
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ database/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ frontend/
â””â”€â”€ ...
```

### Mulighed 3: Som tools mappe
```
minepenge/
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ scraper/               # Scraper som vÃ¦rktÃ¸j
â”œâ”€â”€ frontend/
â”œâ”€â”€ backend/
â””â”€â”€ ...
```

## ğŸš€ Installation i minepenge projektet

### 1. Kopier Scraper mappen
```bash
# Fra minepenge rod
cp -r /path/to/Scraper ./scraper
```

### 2. Installer dependencies
```bash
cd scraper
pip install -r requirements.txt
```

### 3. Test installation
```bash
# Test en enkelt scraper
python scrapers/scraperMoneypenny.py

# Test master script
python update_all_data_realtime.py
```

## ğŸ”— Integration muligheder

### 1. Database Integration
```python
# Eksempel: Import tagged data til minepenge database
import json
from minepenge.database import Article, Tag

def import_tagged_articles():
    with open('data/tagged/tagged_mitteldorf_blog_posts.json', 'r') as f:
        data = json.load(f)
    
    for article_data in data['articles']:
        article = Article(
            title=article_data['title'],
            content=article_data['original_data']['content'],
            summary=article_data['summary'],
            source=article_data['source'],
            url=article_data['url'],
            complexity_level=article_data['complexity_level']
        )
        # Gem artikel og tags...
```

### 2. API Endpoints
```python
# Eksempel: API endpoint til at kÃ¸re scrapers
@app.route('/api/scraper/run', methods=['POST'])
def run_scraper():
    import subprocess
    result = subprocess.run(['python', 'scraper/update_all_data_realtime.py'])
    return {'status': 'success' if result.returncode == 0 else 'error'}

@app.route('/api/scraper/status', methods=['GET'])
def scraper_status():
    # Returner status af seneste kÃ¸rsel
    pass
```

### 3. Scheduled Jobs
```python
# Eksempel: Automatisk opdatering hver dag
from apscheduler.schedulers.background import BackgroundScheduler

scheduler = BackgroundScheduler()
scheduler.add_job(
    func=run_daily_scrape,
    trigger="cron",
    hour=2,  # KÃ¸r kl 2 om natten
    id="daily_scraper"
)
scheduler.start()
```

## ğŸ“Š Data Flow

### NuvÃ¦rende flow:
```
Blogs â†’ Scrapers â†’ Raw JSON â†’ Tagging â†’ Tagged JSON
```

### Integreret flow:
```
Blogs â†’ Scrapers â†’ Raw JSON â†’ Tagging â†’ Tagged JSON â†’ Database â†’ Frontend
```

## ğŸ”§ Konfiguration

### Environment Variables
```bash
# TilfÃ¸j til minepenge .env fil
SCRAPER_DATA_PATH=./scraper/data
SCRAPER_TAGGED_PATH=./scraper/data/tagged
SCRAPER_LOG_LEVEL=INFO
```

### Database Schema
```sql
-- Eksempel pÃ¥ database tabel for artikler
CREATE TABLE articles (
    id SERIAL PRIMARY KEY,
    article_id VARCHAR(50) UNIQUE,
    title TEXT NOT NULL,
    content TEXT,
    summary TEXT,
    source VARCHAR(100),
    url TEXT UNIQUE,
    complexity_level VARCHAR(20),
    target_audiences JSONB,
    minepenge_tags JSONB,
    confidence_scores JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

## ğŸ§ª Testing

### Test scripts individuelt
```bash
cd scraper
python tagging/test_tagger.py
python scrapers/scraperMoneypenny.py
```

### Test fuld integration
```bash
cd scraper
python update_all_data_realtime.py
```

### Test database import
```python
# Test script til at importere data
python -c "
from integration import import_tagged_articles
import_tagged_articles()
"
```

## ğŸ“ˆ Monitoring

### Logging
```python
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('scraper.log'),
        logging.StreamHandler()
    ]
)
```

### Metrics
- Antal artikler scraped per dag
- Tagging accuracy
- Database import success rate
- Scraper performance

## ğŸ”’ Sikkerhed

### Rate Limiting
- Alle scrapers har allerede delays mellem requests
- Respekterer robots.txt

### Error Handling
- Fallback metoder i alle scrapers
- Graceful error handling i master scripts

### Data Validation
- JSON schema validation
- Content quality checks
- Duplicate detection

## ğŸš€ Deployment

### Docker (Valgfrit)
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY scraper/ ./scraper/
RUN pip install -r scraper/requirements.txt

CMD ["python", "scraper/update_all_data_realtime.py"]
```

### Cron Jobs
```bash
# KÃ¸r dagligt kl 2:00
0 2 * * * cd /path/to/minepenge/scraper && python update_all_data_realtime.py
```

## ğŸ“ Support

For spÃ¸rgsmÃ¥l om integration, kontakt udviklingsteamet pÃ¥ minepenge.dk 